{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOi8UCR+YgRjYMesz3CPDy8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoones-vaezi/GATech-CSE6040/blob/master/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "29ffhDFk8XDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28d09ecc-5efd-45a5-bc0f-c7f93c07ae09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets rouge_score evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import string\n",
        "import torch\n",
        "import datasets\n",
        "from datasets import load_from_disk, DatasetDict\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge_score import rouge_scorer\n",
        "from evaluate import load\n",
        "import numpy as np\n",
        "from nltk.stem import PorterStemmer\n",
        "from scipy.spatial.distance import cosine\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "8Nhk9zhf-qNi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RMJ3hY8ycHnF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t5_model_name = 'google-t5/t5-base'\n",
        "max_length = 128"
      ],
      "metadata": {
        "id": "lDF0hwV3-uq5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip 'combined_dataset.zip'"
      ],
      "metadata": {
        "id": "tsz9W2v7_MJz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure necessary NLTK resources are downloaded\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')\n",
        "meteor = load('meteor')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVUu2uzoAdDQ",
        "outputId": "f51b45d7-e528-4f25-9ed9-b54420d877dd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the stemmer for stemming words during text normalization\n",
        "stemmer = PorterStemmer()\n",
        "# Define a consistent max_length for tokenization\n",
        "\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = T5Tokenizer.from_pretrained(t5_model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(t5_model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37PsRpzHAio8",
        "outputId": "b8009d09-3bdf-4c6e-9065-0e4356ef4af3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the custom Seq2SeqDataset class (if needed)\n",
        "class Seq2SeqDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_input_length=max_length, max_target_length=max_length):\n",
        "        self.data = data  # The dataset containing the text examples\n",
        "        self.tokenizer = tokenizer  # The tokenizer for converting text to tokens\n",
        "        self.max_input_length = max_input_length  # Max length for input sequences\n",
        "        self.max_target_length = max_target_length  # Max length for target sequences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)  # Returns the total number of examples in the dataset\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Fetch the original and rephrased questions for the given index\n",
        "        input_text = self.data['original_question'][index]\n",
        "        target_text = self.data['rephrased_question'][index]\n",
        "\n",
        "        # Tokenize the input and target texts\n",
        "        input_ids = self.tokenizer(input_text, padding='max_length', max_length=self.max_input_length, truncation=True, return_tensors='pt').input_ids\n",
        "        target_ids = self.tokenizer(target_text, padding='max_length', max_length=self.max_target_length, truncation=True, return_tensors='pt').input_ids\n",
        "\n",
        "        # Return a dictionary with input and target token IDs\n",
        "        return {'input_ids': input_ids.squeeze(), 'labels': target_ids.squeeze()}"
      ],
      "metadata": {
        "id": "-HcMpA81AlXB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_split_dataset(dataset_path, split_ratios=(0.8, 0.1, 0.1)):\n",
        "    # Load the dataset from the specified path\n",
        "    dataset = load_from_disk(dataset_path)\n",
        "\n",
        "    # Check if the dataset already has 'train', 'validation', and 'test' keys\n",
        "    if all(key in dataset.keys() for key in ['train', 'validation', 'test']):\n",
        "        print(\"Dataset already contains 'train', 'validation', and 'test' splits.\")\n",
        "        return dataset  # Return the existing splits\n",
        "\n",
        "    # If not, perform the splits manually\n",
        "    print(\"Splitting the dataset into 'train', 'validation', and 'test' sets.\")\n",
        "\n",
        "    # Split dataset into training and test sets first\n",
        "    split_dataset = dataset.train_test_split(test_size=split_ratios[2])\n",
        "\n",
        "    # Further split the training set into train and validation sets\n",
        "    temp_dataset = split_dataset['train'].train_test_split(test_size=split_ratios[1] / (split_ratios[0] + split_ratios[1]))\n",
        "\n",
        "    # Combine the splits into a final DatasetDict\n",
        "    final_splits = DatasetDict({\n",
        "        'train': temp_dataset['train'],\n",
        "        'validation': temp_dataset['test'],\n",
        "        'test': split_dataset['test']\n",
        "    })\n",
        "\n",
        "    # Return the split datasets\n",
        "    return final_splits"
      ],
      "metadata": {
        "id": "WX3VsZyaAqU3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure consistent tokenization settings across the script\n",
        "def tokenize_input(texts):\n",
        "    return tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors='pt')"
      ],
      "metadata": {
        "id": "G4Wx_afqAsw8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Preprocess the data using tokenizer\n",
        "def preprocess_data(tokenizer, dataset, max_input_length=max_length, max_target_length=max_length):\n",
        "    # This function tokenizes the input and target sequences in the dataset\n",
        "    def tokenize_function(examples):\n",
        "        # Tokenize the original question\n",
        "        model_inputs = tokenizer(\n",
        "            examples[\"original_question\"],\n",
        "            max_length=max_input_length,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\"\n",
        "        )\n",
        "        # Tokenize the rephrased question and store it as labels\n",
        "        labels = tokenizer(\n",
        "            examples[\"rephrased_question\"],\n",
        "            max_length=max_target_length,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\"\n",
        "        )\n",
        "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "        return model_inputs\n",
        "\n",
        "    # Apply the tokenization function to the dataset\n",
        "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "    return tokenized_dataset"
      ],
      "metadata": {
        "id": "HjRkpOMTAwVA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text normalization function\n",
        "def normalize_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "\n",
        "    # Remove extra whitespaces (e.g., multiple spaces) and trim leading/trailing spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Apply stemming to reduce words to their root form\n",
        "    text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
        "\n",
        "    # Return the normalized text\n",
        "    return text"
      ],
      "metadata": {
        "id": "PYyRHs2aAyQN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute normalized edit distance\n",
        "def compute_normalized_edit_distance(pred, label):\n",
        "    # Calculate the raw Edit Distance\n",
        "    raw_edit_distance = nltk.edit_distance(pred, label)\n",
        "\n",
        "    # Normalize by the length of the longer string\n",
        "    normalized_edit_distance = raw_edit_distance / max(len(pred), len(label))\n",
        "\n",
        "    return normalized_edit_distance"
      ],
      "metadata": {
        "id": "2cABVpM-Az0b"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Define compute_metrics function with proper handling of text-based and embedding-based metrics\n",
        "def compute_metrics(pred):\n",
        "    labels_ids = pred.label_ids\n",
        "    pred_ids = pred.predictions.argmax(-1)\n",
        "\n",
        "    # Load the tokenizer to decode the prediction and label IDs back to text\n",
        "    # tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "\n",
        "    # Decode the predictions and labels into strings\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    labels_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "    # Normalize the decoded strings\n",
        "    pred_str_norm = [normalize_text(text) for text in pred_str]\n",
        "    labels_str_norm = [normalize_text(text) for text in labels_str]\n",
        "\n",
        "    # Compute text-based metrics\n",
        "    bleu_score = np.mean([sentence_bleu([label], pred) for label, pred in zip(labels_str_norm, pred_str_norm)])\n",
        "\n",
        "    rouge_scorer_obj = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "    rouge_scores = [rouge_scorer_obj.score(label, pred) for label, pred in zip(labels_str_norm, pred_str_norm)]\n",
        "    avg_rouge = {metric: np.mean([score[metric].fmeasure for score in rouge_scores]) for metric in rouge_scores[0].keys()}\n",
        "\n",
        "\n",
        "    meteor_scores = meteor.compute(predictions=pred_str_norm, references=labels_str_norm)\n",
        "\n",
        "    edit_distance = np.mean([nltk.edit_distance(pred, label) for pred, label in zip(pred_str_norm, labels_str_norm)])\n",
        "\n",
        "    # Normalized Edit Distance\n",
        "    normalized_edit_distance = np.mean([compute_normalized_edit_distance(pred, label) for pred, label in zip(pred_str_norm, labels_str_norm)])\n",
        "\n",
        "\n",
        "    # Get embeddings for predicted and reference strings using consistent tokenization\n",
        "    pred_embeddings = tokenizer(pred_str, padding=True, truncation=True, max_length=max_length, return_tensors='pt')['input_ids']\n",
        "    labels_embeddings = tokenizer(labels_str, padding=True, truncation=True, max_length=max_length, return_tensors='pt')['input_ids']\n",
        "\n",
        "    # Move embeddings to GPU if available\n",
        "    # if torch.cuda.is_available():\n",
        "    #     pred_embeddings = pred_embeddings.cuda()\n",
        "    #     labels_embeddings = labels_embeddings.cuda()\n",
        "\n",
        "    # Cosine similarity between embeddings\n",
        "    # cosine_sim_scores = [1 - cosine(pred_embedding.cpu(), label_embedding.cpu()) for pred_embedding, label_embedding in zip(pred_embeddings, labels_embeddings)]\n",
        "    # avg_cosine_similarity = np.mean(cosine_sim_scores)\n",
        "\n",
        "    # Compute cosine similarity directly on the GPU using PyTorch\n",
        "    cosine_sim_scores = F.cosine_similarity(pred_embeddings.float(), labels_embeddings.float(), dim=-1)\n",
        "    avg_cosine_similarity = torch.mean(cosine_sim_scores).item()\n",
        "\n",
        "    # Perplexity (logits-based, not embedding-based)\n",
        "    perplexity = torch.exp(torch.mean(pred.predictions))\n",
        "\n",
        "    # Return the computed metrics as a dictionary\n",
        "    return {\n",
        "        'cosine_similarity': avg_cosine_similarity,\n",
        "        'bleu': bleu_score,\n",
        "        'rouge1': avg_rouge['rouge1'],\n",
        "        'rougeL': avg_rouge['rougeL'],\n",
        "        'meteor': meteor_scores['meteor'],\n",
        "        'perplexity': perplexity.item(),\n",
        "        'edit_distance': edit_distance,\n",
        "        'normalized_edit_distance': normalized_edit_distance\n",
        "    }"
      ],
      "metadata": {
        "id": "mTCdpufGA1c4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Set Up the Model and Training Arguments\n",
        "def setup_model_and_args(model_name=\"t5-small\", output_dir=\"./results\", **kwargs):\n",
        "    # Load the T5 model and tokenizer\n",
        "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # Move model to GPU if available\n",
        "    # if torch.cuda.is_available():\n",
        "    #     model.cuda()\n",
        "    # Default training arguments in a dictionary\n",
        "    training_args_dict = {\n",
        "        \"output_dir\":output_dir,  # Output directory for model checkpoints\n",
        "        \"eval_strategy\":'steps',  # Evaluate model at the end of each epoch\n",
        "        \"save_strategy\":'steps',  # Save the model every few steps\n",
        "        \"learning_rate\":5e-5,  # Learning rate for optimizer\n",
        "        \"warmup_steps\":500,\n",
        "        \"per_device_train_batch_size\":16,  # Batch size for training\n",
        "        \"per_device_eval_batch_size\":16,  # Batch size for evaluation\n",
        "        \"weight_decay\":0.01,  # Weight decay to avoid overfitting\n",
        "        \"num_train_epochs\":1,  # Number of training epochs\n",
        "        \"fp16\":False,#torch.cuda.is_available(),  # Enable mixed precision training if a GPU is available\n",
        "        \"logging_dir\":'./logs_combined',  # Directory for storing logs\n",
        "        \"logging_steps\":1000,  # Log training progress every 10 steps\n",
        "        \"eval_steps\":1000,  # Evaluate the model every 500 steps\n",
        "        \"save_steps\":5000,  # Save model checkpoint every 500 steps\n",
        "        \"load_best_model_at_end\":True,  # Load the best model found during training\n",
        "        # \"metric_for_best_model\": \"cosine_similarity\",  # Example: Monitor BLEU score to save the best model\n",
        "        # \"greater_is_better\": True,  # Set to False if a lower value is better (e.g., for loss)\n",
        "        \"metric_for_best_model\": \"eval_loss\",\n",
        "        \"greater_is_better\": False,\n",
        "    }\n",
        "\n",
        "    # Update the dictionary with any provided kwargs\n",
        "    training_args_dict.update(kwargs)\n",
        "\n",
        "    # Pass the updated dictionary to TrainingArguments\n",
        "    training_args = TrainingArguments(**training_args_dict)\n",
        "\n",
        "    # Return the model, tokenizer, and training arguments\n",
        "    return model, tokenizer, training_args"
      ],
      "metadata": {
        "id": "xWTrczdoBXnc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Initialize Trainer and Data Collator\n",
        "def initialize_trainer(model, tokenizer, tokenized_dataset, training_args):\n",
        "    # Define the data collator to dynamically pad the sequences during batching\n",
        "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "    # Initialize the Trainer class with the model, arguments, datasets, tokenizer, and data collator\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_dataset[\"train\"],  # Training dataset\n",
        "        eval_dataset=tokenized_dataset[\"validation\"],  # Validation dataset\n",
        "        tokenizer=tokenizer,  # Tokenizer to decode the predictions\n",
        "        data_collator=data_collator,  # Data collator for padding\n",
        "        # compute_metrics=compute_metrics  # Function to compute evaluation metrics\n",
        "    )\n",
        "\n",
        "    # Return the initialized Trainer\n",
        "    return trainer"
      ],
      "metadata": {
        "id": "xMfje5Z1Bgvg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Train the Model and Evaluate\n",
        "def train_and_evaluate_model(trainer):\n",
        "    trainer.train()\n",
        "    eval_results = trainer.evaluate()\n",
        "    return eval_results\n",
        "\n",
        "# 8. Save the Model and Tokenizer\n",
        "def save_model_and_tokenizer(trainer, tokenizer, output_dir=\"./fine_tuned_t5\"):\n",
        "    trainer.save_model(output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)"
      ],
      "metadata": {
        "id": "UHlDZCqYBmvO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function to orchestrate the fine-tuning process\n",
        "def fine_tune_t5(dataset_path, output_dir=\"./fine_tuned_t5\",model_name='t5_small',split_ratios=(0.8, 0.1, 0.1), **training_args):\n",
        "    dataset_splits = load_and_split_dataset(dataset_path, split_ratios)\n",
        "    model, tokenizer, training_args = setup_model_and_args(\n",
        "        model_name=model_name,\n",
        "        output_dir=output_dir,\n",
        "        **training_args\n",
        "    )\n",
        "    tokenized_dataset = preprocess_data(tokenizer, dataset_splits)\n",
        "    trainer = initialize_trainer(model, tokenizer, tokenized_dataset, training_args)\n",
        "\n",
        "    # Train and Evaluate\n",
        "    eval_results = train_and_evaluate_model(trainer)\n",
        "    print(f\"Evaluation results: {eval_results}\")\n",
        "\n",
        "    # Save Model and Tokenizer\n",
        "    save_model_and_tokenizer(trainer, tokenizer, output_dir)\n",
        "\n",
        "    # Plot losses\n",
        "    # plot_train_validation_losses(trainer)\n",
        "\n",
        "    # Plot evaluation metrics\n",
        "    # plot_evaluation_metrics(trainer)\n",
        "\n",
        "    return trainer, eval_results"
      ],
      "metadata": {
        "id": "ItbTjsCRBoVd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer, results = fine_tune_t5(\n",
        "        \"combined_dataset\",\n",
        "        output_dir=f\"./fine_tuned_{t5_model_name.replace('/','-')}_combined\",\n",
        "        model_name = t5_model_name,\n",
        "        split_ratios=(0.8, 0.1, 0.1),\n",
        "        num_train_epochs=5,\n",
        "        use_cpu = False,\n",
        "        learning_rate=3e-5,  # Override the default learning rate\n",
        "        per_device_train_batch_size=32,\n",
        "        per_device_eval_batch_size=32,\n",
        "        logging_steps=1000,  # Log training progress every 10 steps\n",
        "        eval_steps=1000,  # Evaluate the model every 500 steps\n",
        "        save_steps=5000,  # Save model checkpoint every 500 steps\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 984
        },
        "id": "ODQZaTVRBsqM",
        "outputId": "e2ae7bb6-d588-4560-e2b4-2fae3fedefc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset already contains 'train', 'validation', and 'test' splits.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6575' max='37630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 6575/37630 2:02:21 < 9:38:06, 0.90 it/s, Epoch 0.87/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>2.134500</td>\n",
              "      <td>0.205194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.208400</td>\n",
              "      <td>0.193325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.199100</td>\n",
              "      <td>0.187871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.193400</td>\n",
              "      <td>0.184697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.189600</td>\n",
              "      <td>0.182442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.186700</td>\n",
              "      <td>0.180681</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20411' max='37630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20411/37630 6:25:42 < 5:25:25, 0.88 it/s, Epoch 2.71/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>2.134500</td>\n",
              "      <td>0.205194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.208400</td>\n",
              "      <td>0.193325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.199100</td>\n",
              "      <td>0.187871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.193400</td>\n",
              "      <td>0.184697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.189600</td>\n",
              "      <td>0.182442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.186700</td>\n",
              "      <td>0.180681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.184400</td>\n",
              "      <td>0.179279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.182500</td>\n",
              "      <td>0.178135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.179900</td>\n",
              "      <td>0.177150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.178400</td>\n",
              "      <td>0.176093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.177400</td>\n",
              "      <td>0.175256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.175700</td>\n",
              "      <td>0.174685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.176200</td>\n",
              "      <td>0.173943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.175700</td>\n",
              "      <td>0.173628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.174900</td>\n",
              "      <td>0.173005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.171100</td>\n",
              "      <td>0.172839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>0.170800</td>\n",
              "      <td>0.172508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18000</td>\n",
              "      <td>0.170100</td>\n",
              "      <td>0.172107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19000</td>\n",
              "      <td>0.170600</td>\n",
              "      <td>0.171843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>0.171000</td>\n",
              "      <td>0.171446</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model_folder_final = f\"./fine_tuned_{t5_model_name.replace('/','-')}_combined_final\"\n",
        "trainer.save_model(saved_model_folder_final)\n",
        "tokenizer.save_pretrained(saved_model_folder_final)\n"
      ],
      "metadata": {
        "id": "uqHkSpS0fERp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_state()"
      ],
      "metadata": {
        "id": "-W1Jc_LHp4-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "548sheWnp14b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#shutil.rmtree('/content/fine_tuned_t5-base_hotpotqa/checkpoint-14000')"
      ],
      "metadata": {
        "id": "58Rd2VVplL6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "saved_model_folder_final = f\"./fine_tuned_{t5_model_name.replace('/','-')}_combined_final\"\n",
        "model_folder_name = saved_model_folder_final\n",
        "zip_name = model_folder_name+'.zip'\n",
        "shutil.make_archive(model_folder_name,'zip',model_folder_name)\n",
        "files.download(zip_name)"
      ],
      "metadata": {
        "id": "C9mOyuMGRma3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IKNjmiyQcP7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_train_validation_losses(trainer, save_path=None):\n",
        "    train_loss = trainer.state.log_history\n",
        "    steps = range(len(train_loss))\n",
        "    train_losses = [x['loss'] for x in train_loss if 'loss' in x]\n",
        "    eval_losses = [x['eval_loss'] for x in train_loss if 'eval_loss' in x]\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plotting both training and validation losses on the same plot\n",
        "    plt.plot(steps[:len(train_losses)], train_losses, label='Training Loss', color='blue')\n",
        "    plt.plot(steps[:len(eval_losses)], eval_losses, label='Validation Loss', color='orange')\n",
        "\n",
        "    plt.xlabel('Steps')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Save the plot if save_path is provided\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "wcweosazrO9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig_name = './t5_base_combined.png'\n",
        "plot_train_validation_losses(trainer, save_path=fig_name)\n",
        "files.download(fig_name)"
      ],
      "metadata": {
        "id": "PLGbVxs3rQkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_loss_dataframe(trainer):\n",
        "    # Initialize lists to store the steps and corresponding losses\n",
        "    steps = []\n",
        "    train_losses = []\n",
        "    eval_losses = []\n",
        "\n",
        "    # Loop through the log history to extract the relevant data\n",
        "    for log in trainer.state.log_history:\n",
        "        if 'loss' in log:\n",
        "            steps.append(log['step'])\n",
        "            train_losses.append(log['loss'])\n",
        "            eval_losses.append(None)  # No evaluation loss for this step\n",
        "        elif 'eval_loss' in log:\n",
        "            steps.append(log['step'])\n",
        "            train_losses.append(None)  # No training loss for this step\n",
        "            eval_losses.append(log['eval_loss'])\n",
        "\n",
        "    # Create a DataFrame from the collected data\n",
        "    df = pd.DataFrame({\n",
        "        'step': steps,\n",
        "        'train_loss': train_losses,\n",
        "        'eval_loss': eval_losses\n",
        "    })\n",
        "\n",
        "    # Fill forward the train_loss to align with corresponding eval_loss\n",
        "    df['train_loss'] = df['train_loss'].fillna(method='ffill')\n",
        "\n",
        "    return df\n",
        "\n",
        "# Example usage:\n",
        "df_losses = create_loss_dataframe(trainer)\n",
        "print(df_losses)"
      ],
      "metadata": {
        "id": "rnkKoaEMTPAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_df_file_name = 't5_base_combined.csv'\n",
        "df_losses.to_csv(loss_df_file_name,index=False)\n",
        "files.download(loss_df_file_name)"
      ],
      "metadata": {
        "id": "eOm0hZxTTR7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import runtime\n",
        "\n",
        "# runtime.unassign()"
      ],
      "metadata": {
        "id": "KYSotpZtSd65"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}